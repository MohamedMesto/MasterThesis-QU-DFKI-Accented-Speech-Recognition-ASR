\chapter{Introduction}
\label{cha:introduction}
\section{Motivation}

In this paper, we will address the main engine in the field of neural networks\cite{dai2019transformer,devlin2018bert,raffel2020exploring} in general and automatic speech recognition in particular, which is transformers\cite{vaswani2017attention}. What contributed to her gaining this reputation is the multi-head self-attention approach, which instantly provides a high-handed position connection in parallel for the entire series, Instead of utilizing memory conditions to catch long-range dependencies in recurrent neural networks.

Nevertheless, the noteworthy transformer-based model architectures in automatic speech recognition (ASR) are Connectionist temporal classification (CTC)\cite{salazar2019self,zhang2020faster},
sequence-to- sequence \cite{dong2018speech,karita2019comparative,sperber2018self,zhou2018syllable,wang2020low}, Neural transducer \cite{zhang2020transformer,yeh2019transformer,gulati2020conformer} and traditional hybrid systems\cite{wang2020transformer,povey2018time}.


The results of the tests carried out on the public LibriSpeech showed a resounding success. The Emformer achieved a very low Word Error Rate (WER) in the clean-up test for a certain average latency \cite{shi2021emformer}. Nevertheless, One of the promising technologies in this field is the Transformer Transducer. It exceeded the neural transducer with the Long-Short Term Memory (LSTM) or the Bidirectional Long-Short Term Memory (BLSTM) networks and achieved a surprising WER on the test-clean set and the test-other set.\cite{yeh2019transformer}. Moreover, One of the new technologies that grabbed the spotlight was the wav2vec2 pretrained model. It supported the ASR Systems in the Dysarthric speech recognition field\cite{karthick2022speaker}. 


\subsection{Improved/significantly improved}
\section{Background}
text .... Wikipedia \footnote{https://www.wikipedia.org/}




\section{Problem Statement}

 

\section{Outline}

