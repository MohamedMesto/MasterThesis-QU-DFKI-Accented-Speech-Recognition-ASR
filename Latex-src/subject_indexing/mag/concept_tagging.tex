\subsubsection{Concept tagging} \label{mag_concept_tagging}

Tagging concepts to publications is performed by solving a multi-label classification problem. Heuristics are applied to reduce the number of candidate pairs between concepts and publications, as evaluating every possible pair is unfeasible. All concepts of the first two levels as well as the concepts present in the publication's \acrfull{ert} are included in the classification task. The \acrshort{ert} is an extension of the text that describes an entity, termed \acrfull{srt}, to include textual information from its neighboring nodes in the \acrshort{mag}. Four representations of each \acrshort{ert} are concatenated and used as its vector representation: bag-of-words, bag-of-entities, embedding-of-words and embedding-of-entities. Words are also embedded as vectors using a skip-gram model \cite{mikolov2013distributed} that was pre-trained on an academic corpus.

To assign an \acrshort{ert} to each concept, the authors first manually assigned venues to concepts. The \acrshort{ert} of each concept is then the aggregation of the \acrshort{ert}s of the venues it was assigned. The mapping of venues to concepts is not available online. Once all publications and concepts are embedded (both as \acrshort{ert}s), a confidence score for each pair of concept and \acrshort{ert} is computed as the cosine similarity between their vector representations. The authors computed confidence scores for 50 billion pairs and kept one billion of them.