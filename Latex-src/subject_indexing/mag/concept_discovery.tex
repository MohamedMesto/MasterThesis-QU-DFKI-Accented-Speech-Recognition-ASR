\subsubsection{Concept discovery} \label{mag_concept_discovery}

Given the vast amount of publications that appear every year (a number that doubles every dozen years \cite{dong2017century}), manually curating concepts is not a possibility anymore. A large amount of concepts is needed to properly characterize every document. Temporal dynamics (i.e. how research focus shifts over time) should also be monitored. This requires regular updates of the concept model, which again hinders the manual approach to solving the task.

Microsoft Research has adopted a hybrid approach for discovering concepts. They have manually defined the first two levels of the concept model (i.e. the two broadest levels) as well as 2000 other high-quality concepts, and solved the \textit{knowledge base type prediction} problem to assist them in discovering more specific concepts from the Wikipedia knowledge base. Their approach iterates between \textit{graph link analysis} for discovering potential concepts and \textit{entity type based filtering and enrichment}, which selects the most appropriate concepts out of the candidates retrieved in the previous step. The iteration is executed a few times, without any particular stopping criterion.

Graph link analysis explores concept candidates by assuming that the nearest neighbors of a concept are also concepts. Similarity between Wikipedia entities is defined based on the amount of hyperlinks to other entities that they share \cite{witten2008effective}. In the second step of the loop, the candidate concepts are filtered based on their type. Entities that belong to types which are irrelevant for the concept model, such as \textit{person}, are removed. Then, all other Wikipedia entities of the remaining types are added to the list of candidates. Which types are valid is determined using an undisclosed knowledge base.