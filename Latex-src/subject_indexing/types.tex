\subsection{Classifications of methods} \label{subject_indexing_types}

% Subject indexing methods can be classified in various manners. For instance, approaches can be classified regarding the origin of the used subjects \cite{golub2019automatic}. Derived \acrshort{si} extracts the subjects from the document itself, while assigned \acrshort{si} maps a fixed set of subjects to the given document.

In this section, we give an overview of the different classifications of \acrshort{si} methods that we have found in the literature. They all revolve around the existence of a \acrfull{kos}, and the availability of training data.

\input{subject_indexing/types/golub}
\input{subject_indexing/types/medelyan}
\input{subject_indexing/types/toepfer}


\subsubsection{Comparison of classifications}

The usage of a \acrshort{kos} and the requirement of training data are the two distinguishing factors of the classifications. These are summarized in table \ref{tab:subject_indexing_classifications}. We will now look at them as a whole and establish relationships between them when possible.

\begin{table}
\centering
\begin{tabular}{|c|c|c|c|c|}
\hline
\thead{Author} & \thead{Group} & \thead{KOS} & \thead{Tr. data} & \thead{Method} \\
\hline\hline
\multirow{3}{*}{Golub} & Text categorization & Yes & Yes & ML algorithm \\ \cline{2-5}
& Document clustering & No & No & ML algorithm \\ \cline{2-5}
& Document classification & Yes & No & String matching \\ \cline{2-5}
\hline
\multirow{3}{*}{Medelyan} & Keyphrase extraction & No & No & String matching \\ \cline{2-5}
& Term assignment & Yes & Yes & Any \\ \cline{2-5}
& Keyphrase indexing & Yes & Yes & ML algorithm \\ \cline{2-5}
\hline
\multirow{3}{*}{Töpfer} & Associative methods & Yes & Yes & ML algorithm \\ \cline{2-5}
& Lexical methods & Yes & Yes & Both \\ \cline{2-5}
& Fusion architecture & Yes & Yes & Both \\ \cline{2-5}
\hline
\end{tabular}
\caption{Summary of the SI classifications.}
\label{tab:subject_indexing_classifications}
\end{table}

Golub's \textit{document clustering} and Medelyan's \textit{keyphrase extraction} are the only categories that require neither a \acrshort{kos} nor assigned documents as training data. They differ mainly in their objective: document clustering focuses on the subjects that relate documents, whereas keyphrase extraction looks at each document individually, looking for its most significant subjects.

Töpfer mentions Medelyan's models (KEA++ \cite{medelyan2008domain} and Maui \cite{medelyan2009human}) as examples of \textit{lexical methods}. Given that, according to Medelyan's classification, they belong to the \textit{keyphrase indexing} category, we can establish a relationship among these two categories. Furthermore, \textit{keyphrase indexing} arises from combining the other two categories of Medelyan's classification (\textit{term assignment} and \textit{keyphrase extraction}). Therefore, all three categories from Medelyan can be placed under Töpfer's lexical methods. Golub's \textit{text categorization} also requires training data and a \acrshort{kos}, and uses an \acrshort{ml} algorithm as well.

Finally, Medelyan mentions that \textit{term assignment} methods only require training data if an \acrshort{ml} algorithm is going to be used. If string matching is used, no training data is required. In this case, \textit{term assignment} would be equivalent to Golub's \textit{document classification} category, where the \acrshort{kos} is expected to be large enough for its entries to appear verbatim in the documents.

Considering all these similarities, we can identify three main types of \acrshort{si} methods. Those that require neither training data nor a \acrshort{kos}, those that only require a \acrshort{kos} and those that require both a \acrshort{kos} and training data.