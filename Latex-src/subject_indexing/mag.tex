\subsection{Microsoft Academic Graph} \label{subject_indexing_mag}

The \acrfull{mag} is a knowledge base whose aim is to semantically relate scientific publications to one another \cite{shen2018web}. Its nodes can be of one of six types: publication, author, institution, journal, conference and concept. Having a high-quality concept model is detrimental and has been the main focus of Microsoft Research. The research group has developed throughout the past five years a concept hierarchy model which is used to semantically categorize scientific publications. Their pipeline comprises three steps. First, concepts are discovered; these concepts are then assigned to documents when semantically appropriate; finally, the relationships between the documents are used to build a concept hierarchy. We will now look at each of these steps more in detail.

\begin{table}
\begin{center}
    \begin{tabular}{| p{1.6cm} | p{2.9cm} | p{2.7cm} | p{2.3cm} |} 
    \hline
     & \thead{Concept \\ discovery} & \thead{Concept \\ tagging} & \thead{Hierarchy \\ building} \\ [0.5ex] 
    \hline\hline
    \thead{Problem} & \makecell{knowledge base \\ type prediction} & \makecell{multi-label text \\ classification} & \makecell{topic hierarchy \\ construction} \\ 
    \hline
    \thead{Solution} & \makecell{graph link analysis \\ on Wikipedia} & \makecell{word embeddings \\ + \\ graph structure} & \makecell{extended \\ subsumption} \\
    \hline
    \thead{Test \\ accuracy} & \makecell{94.75 \%} & \makecell{81.20 \%} & \makecell{78.00 \%} \\
    \hline
    \end{tabular}
    \caption{Summary of each phase of the \acrshort{mag} development.}
    \label{tab:mag}
\end{center}
\end{table}

Before introducing each of these steps, we explain the word embedding model they use, called skip-gram \cite{mikolov2013distributed}, which is the key component of their procedure. The word embeddings are trained by comparing them with the embeddings of the word that surround it in the text. Thus, embeddings are trained locally, focusing on the context of each word, rather than globally, where statistics and other metrics that consider the data as a whole are introduced.

After outlining \acrshort{mag}'s three steps, we introduce the two ways in which its data can be accessed. The \acrfull{makg} \cite{faerber2019microsoft} offers the data in RDF files, which are suitable for analysis tasks and efficient exploration. The second option is an expressive \acrshort{api}, provided by OpenAlex, which offers granular access to the documents and subjects. It also includes all the subject assignments, whereas the \acrshort{makg} only assigns fields. Therefore, we will use OpenAlex in this thesis.

\input{subject_indexing/mag/skipgram}
\input{subject_indexing/mag/concept_discovery}
\input{subject_indexing/mag/concept_tagging}
\input{subject_indexing/mag/hierarchy}
\input{subject_indexing/mag/updates}

\subsubsection{Accessing the data} \label{mag_access_data}

Microsoft provides \acrshort{api} access\footnote{\url{https://docs.microsoft.com/en-us/academic-services/project-academic-knowledge/reference-evaluate-method}} to their corpus, including already tokenized abstracts and the subjects of each document. A subscription is required to access the \acrshort{api} endpoint and the rate limit is set to 10,000 transactions per month and 1 per second. Unfortunately, the \acrshort{mag} service was shut down at the end of 2021. We therefore discuss two other options, that also offer \acrshort{mag} data, in the following sections. We then close this chapter by arguing our choice between them.

\input{subject_indexing/mag/makg}
\input{subject_indexing/mag/openalex}
\input{subject_indexing/mag/choice}

